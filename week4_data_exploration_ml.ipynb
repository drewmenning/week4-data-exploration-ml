# Week 4: Data Exploration, Feature Engineering, and Modeling

## This notebook explores a real-world dataset, applies feature engineering techniques, and trains a simple machine learning model using scikit-learn.

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from sklearn.datasets import fetch_openml

adult = fetch_openml(name="adult", version=2, as_frame=True)
df = adult.frame

df.head()

df.info()
df.describe()
df.isnull().sum()

# The dataset contains both numerical and categorical features. The target variable is `class`, which represents income level.

df['age'].hist(bins=20)
plt.title("Age Distribution")
plt.xlabel("Age")
plt.ylabel("Frequency")
plt.show()

plt.scatter(df['hours-per-week'], df['age'], alpha=0.3)
plt.xlabel("Hours per Week")
plt.ylabel("Age")
plt.title("Hours Worked vs Age")
plt.show()

# One-hot encode categorical variables
df_encoded = pd.get_dummies(df, drop_first=True)

# Create a new feature
df_encoded['long_hours'] = (df_encoded['hours-per-week'] > 40).astype(int)

df_encoded.head()

# Categorical variables were encoded using one-hot encoding.  
A new feature (`long_hours`) was created to capture employees who work more than 40 hours per week.

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

X = df_encoded.drop('class_>50K', axis=1)
y = df_encoded['class_>50K']

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

model = LogisticRegression(max_iter=1000)
model.fit(X_train, y_train)

y_pred = model.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)

accuracy

# The model achieved reasonable accuracy for a simple baseline classifier. Feature engineering helped improve performance by making categorical data usable and adding an informative derived feature.

# One challenging part of this assignment was deciding which features to engineer and how much transformation was necessary. It was surprising how much impact simple encoding had on model performance.

Feature engineering choices directly affected how well the model could learn patterns in the data. Adding the `long_hours` feature helped capture work behavior that may relate to income.

Next time, I would experiment with additional engineered features, try different models, and use pipelines to better organize preprocessing and modeling steps.
